## <img src="/Images/Icons/peer_review.png" width="300" height="300" />

## 8. Açık Hakem/Akran Değerlendirmesi, Ölçevler ve Ölçüm

### Nedir?

Araştırmacı olmak, kendini sürekli değerlendirme altında bulmaktır. Akademi, bir akademisyenin değerinin kendisine ve katkılarına akranları, karar vericiler ve diğerleri tarafından atfedilen itibar düzeylerinin değerlendirilmesine dayanan bir "prestij ekonomisidir" \([Blackmore ve Kandiko, 2011](https://doi.org/10/fqrkft)\). Dolayısıyla bu bölümde, bir çalışmanın değerlendirilmesi ile araştırmacıların kendilerinin değerlendirilmesi arasında ayrım yapmak faydalı olacaktır. Araştırmalar da araştırmacılar da iki temel yöntemle değerlendirilir: İlki nitel, ikinsisi nicel olan hakem/akran değerlendirmesi ve ölçevler. 

Hakem/akran değerlendirmesi araştırmalarla ilgili karar vermek için öncelikli olarak kullanılmaktadır. Bilimsel çıktıların \(örneğin, dergi makaleleri, kitaplar, hibe başvuruları ve konferans bildirileri\) başkalarının incelemesine tabi tutulduğu ve bu kişilerin geri bildirimlerinin ve kararlarının sonrasında çalışmaların iyileştirilmesi ve (yayınların, hibe tahsislerinin ve konuşma sürelerinin) seçimi ile ilgili son kararın verilmesi amacıyla kullanıldığı resmi nitelik güvencesi mekanizmasıdır. Açık hakem/akran değerlendirmesi farklı kişiler ve topluluklar için farklı anlamlara gelmekte ve "hakem/akran değerlendirmesi modellerinin açık bilimin amaçları doğrultusunda uyarlanabileceği örtüşen bir dizi yöntem için şemsiye terim" olarak tanımlanmaktadır \([Ross-Hellauer, 2017](https://doi.org/10/gc5sjh)\). İki temel özelliği, yazarların ve hakemlerin biribirlerini bildiği \(yani, körleme olmayan\) "açık kimlikler (open identities)" ile değerlendirme/hakem raporlarının ilgili makale ile birlikte yayımlandığı "açık raporlardır (open reports)". Bu özellikler, şart olmasa da birleştirilebilir ve daha geniş topluluk üyelerinin değerlendirme sürecine katkıda bulanabilecekleri "açık katılım (open participation)",  yazar\(lar\) ile hakemler arasında ve/veya hakemlerin kendi içinde doğrudan karşılıklı tartışmaya olanak veren ve teşvik eden "açık etkileşim (open interaction)" ve çalışmaların herhangi bir resmi hakem/akran değerlendirme sürecinden önce \(dergi iş akışlarının dahili bir parçası olarak ya da harici olarak önbaskı (preprint) sunucuları aracılığıyla\) hemen erişime sunulduğu "açık ön değerlendirme çalışmaları (open pre-review manuscripts)" gibi diğer yenilikçi yaklaşımlarla tamamlanabilir. 

Hakem/akran değerlendirmesini geçmiş araştırma yayınları ("yayınla ya da yok ol" ifadesi dolayısıyla) genellikle bir araştırmacının çalışmasının birincil ölçüsüdür. Ancak, yayınların kalitesini değerlendirme işi zor ve özneldir. Birleşik Krallık'taki "Research Excellence Framework" gibi bazı genel değerlendirme uygulamaları hakem/akran değerlendirmesi kullansa da, genel değerlendirme sıklıkla yayınların topladığı atıf sayısı (h-indeks), hatta  (Dergi Etki Faktörü ile ölçülen) yayınlandığı derginin algılanan prestij düzeyi gibi __ölçevlere__ dayalıdır.

Son yıllarda "Alternatif Ölçevler" ya da [altmetrics](https://www.altmetric.com), yer imleri, bağlantılar, blog gönderileri, tweet'ler, beğeniler, paylaşımlar, basında yer alan haberler ve benzerleri de dahil olmak üzere, araştırma etkisinin diğer çevrimiçi ölçütlerini de  dikkate alıp atıf saymayı tamamlayarak, araştırma çalışmalarının dengeli bir biçimde değerlendirilmesi ile ilgili tartışmaların konusu haline gelmiştir. Ölçevlerle ilgili tüm bu sorunların temelinde, şeffaflıkla ilgili bazı problemlere yol açabilecek özel sistemlere olarak dayalı ticari kuruluşlar tarafından (örneğin, Clarivate Analytics ve Elsevier) üretilmeleri yatmaktadır.

## <img src="/Images/Icons/umbrella.png" width="150" height="150" />
### Gerekçe

#### Açık hakem değerlendirmesi
17. yüzyılda Royal Society of London (1662) ve Académie Royale des Sciences de Paris (1699) ile bilimin ayrıcalığı olarak kiliseden ziyade kendisini sansürlemesiyle başlayarak, bilimde hakem/akran değerlendirmesinin düzgün bir şekilde yerleşmesi uzun yıllar almıştır. Resmi bir mekanizma olarak hakem/akran değerlendirmesi, varsayılandan çok daha yenidir. Örneğin, Nature dergisinde 1967'de başlamıştır. Anketler, araştırmacıların hakem/akran değerlendirmesine değer verdiğini ama aynı zamanda daha iyi çalışabileceğini düşündüklerini göstermektedir. Sıklıkla hakem/akran değerlendirmelerinin çok uzun sürdüğüne, tutarsız olduğuna ve çoğu zaman hataları tespit edemediğine ve anonim olmasının önyargılardan koruduğuna ilişkin şikayetler olmaktadır. Açık hakem/akran değerlendirmesi, bu nedenle, daha fazla şaffaflık getirmeyi ve resmi ve resmi olmayan hakem/akran değerlendirmesi sürecine katılımı amaçlamaktadır. Hakem/akran olmak, araştırmacılara, yeni araştırmalarla ilgilenme, akademik ağlar ve uzmanlık oluşturma ile yazma becerilerini geliştirme fırsatı sunar. Akademik çalışmalar için kalite kontrolün çok önemli bir unsurudur. Yine de, genel olarak, araştırmacılar hakem/akran değerlendirmesinin nasıl yapılacağı konusunda resmi bir eğitim almazlar. Bununla birlikte, araştırmacıların geleneksel hakem değerlendirmesinden emin olduklarına inandıkları yerlerde bile, açık hakem/akran değerlendirmesininin birçok biçimi yeni zorluklar ve fırsatlar sunmaktadır. Açık hakem/akran değerlendirmesi çok çeşitli uygulamalar içerdiğinden, değerlendiricilerin ve yazarların dikkate alması gereken birçok husus vardır.

## <img src="/Images/02 Open Science Basics/02_open_peer_review.png" />

Değerlendirme ile ilgili olarak, bilim ve akademideki mevcut müfakat ve ölçevler \(henüz\) açık bilime adapte edilmemiştir. Araştırmaları değerlendirmek için kullanılan ölçevler \(örneğin, Dergi Etki Faktöürü, h-indeks\) açık bilim pratiklerini ölçmemekte ve dolayısıyla mükafatlandırmamaktadır. Açık hakem/akran değerlendirmesi aktiviteleri, profesyonel ilerleme senaryolarında  zaruri biçimde "mesleki/bilimsel etkinlik" olarak tanınmamaktadır \(örneğin çoğu durumda, hibe başvurusu hakemleri en parlak açık hakem değerlendirmelerini bile kendileri için bilimsel örnekler olarak görmezler). Ayrıca, birçok değerlendirme ölçevi - özellikle belirli bibliyometrik ölçev türleri - topluluğun arzu ettiği ölçüde açık ve şeffaf değildir.

Bu koşullar altında, açık bilim uygulamaları, en iyi ihtimalle mükafatı olmayan ek bir yük olarak görülmektedir. En kötü ihtimalle, gelecekteki fonlama ve terfilerle birlikte kadro bulma şansına aktif olarak zarar vereceği düşünülmektedir. Yakın zamanlı  bir [Avrupa Komisyonu raporu (2017)](https://doi.org/10.2777/75255) açık bilimin uygulanması için iki temel yaklaşım olduğunu ve ödüllendirme ve değerlendirmenin bunları destekleyebileceğini kabul etmektedir:

1. Daha fazla açıklığı teşvik ederek, ilgili ölçevler oluşturup, çıktıları nicelleştirerek mevcut durumu destekleyin;

2. Alternatif araştırma uygulamaları ve değerlendirmeler, açık veri, yurttaş bilimi ve açık eğitimi tecrübe edin.

Gttikçe daha fazla sayıda fon sağlayıcı ve kurum, örneğin, basitçe saymadan uzaklaşıp, değerlendirme uygulamalarına toplumsal etki anlatılarını ve göstegelerini dahil ederek,   bu yönde adım atmaktadır. Fon sağlayıcılar tarafından atılan diğer adımlar, \(önbaskılar-preprints gibi\) daha fazla sayıda araştırma çıktısına uygulamada izin vermek ve \(tekrar çalışmaları-replication studies gibi\) farklı araştırma türlerini fonlamaktır.

## <img src="/Images/Icons/finish.png" width="150" height="150" />
### Öğrenme hedefleri

1. Recognise the key elements of open peer review and their potential advantages and disadvantages
2. Understand the differences between types of metrics used to assess research and researchers
3. Engage with the debate over the way in which evaluation schema affect the ways in which scholarship is performed

### Temel unsurlar
## <img src="/Images/Icons/brain.png" width="150" height="150" />
### Bilgi
#### Açık hakem değerlendirmesi

Popular venues for OPR include journals from publishers like Copernicus, Frontiers, BioMed Central, eLife and F1000research.

Open peer review, in its different forms, has many potential advantages for reviewers and authors:

* Open identities \(non-blinded\) review fosters greater accountability amongst reviewers and reduces the opportunities for bias or undisclosed conflicts of interest.

* Open review reports add another layer of quality assurance, allowing the wider community to scrutinize reviews to examine decision-making processes.

* In combination, open identities and open reports are theorized to lead to better reviews, as the thought of having their name publicly connected to a work or seeing their review published encourages reviewers to be more thorough.

* Open identities and open reports enable reviewers to gain public credit for their review work, thus incentivising this vital activity and allowing review work to be cited in other publications and in career development activities linked to promotion and tenure.

* Open participation could overcome problems associated with editorial selection of reviewers \(e.g., biases, closed-networks, elitism\). Especially for early career researchers who do not yet receive invitations to review, such open processes may also present a chance to build their research reputation and practice their review skills.

There are some potential pitfalls to watch out for, including:

* Open identities removes anonymity conditions for reviewers \(single-blind\) or authors and reviewers \(double-blind\) which are traditionally in place to counteract social biases \(although there is not strong-evidence that such anonymity has been effective\). It’s therefore important for reviewers to constantly question their assumptions to ensure their judgements reflect only the quality of the manuscript, and not the status, history, or affiliations of the author\(s\). Authors should do the same in receiving peer review comments.

* Giving and receiving criticism is often a process fraught with unavoidably emotional reactions - authors and reviewers may subjectively agree or disagree on how to present the results and/or what needs improvement, amendment or correction. In open identities and/or open reports, the transparency could exacerbate such difficulties. It is therefore essential that reviewers ensure that they communicate their points in a clear and civil way, in order to maximise the chances that it will be received as valuable feedback by the author\(s\).

* Lack of anonymity for reviewers in open identities review might subvert the process by discouraging reviewers from making strong criticisms, especially against higher-status colleagues.

* Finally, given these issues, potential reviewers may be more likely to decline to review.

#### Açık ölçevler

The [San Francisco Declaration on Research Assessment \(DORA\)](https://sfdora.org/) recommends moving away from journal based evaluations, consider all types of output and use various forms of metrics and narrative assessment in parallel. DORA has been signed by thousands of researchers, institutions, publishers and funders, who have now committed themselves to putting this in practice. The [Leiden Manifesto](http://www.leidenmanifesto.org/) provides guidance on how to use metrics responsibly.

Regarding Altmetrics, [Priem et al. (2010)](http://altmetrics.org/manifesto/) advise that altmetrics have the following benefits: they accumulate quicker than citations; they can gauge the impact of research outputs other than journal publications (e.g. datasets, code, protocols, blog posts, tweets, etc.); and they can provide diverse measures of impact for individual objects. The timeliness of altmetrics presents a particular advantage to early-career researchers, whose research-impact may not yet be reflected in significant numbers of citations, yet whose career-progression depends upon positive evaluations. In addition, altmetrics can help with early identification of influential research and potential connections between researchers. A recent report by the EC’s Expert Group on Altmetrics ([Wilsdon et al. (European Commission), 2017](https://ec.europa.eu/research/openscience/pdf/report.pdf)) identified challenges of altmetrics, including lack of robustness and susceptibility to ‘gaming’; that any measure ceases to be a good measure once it becomes a target (‘Goodhart’s Law’); relative lack of social media uptake in some disciplines and geographical regions; and a reliance on commercial entities for the underlying data.

## <img src="/Images/Icons/gears.png" width="150" height="150" />
### Beceriler

Example exercises

* Trainees work in groups of three. Each individually writes a review of a short academic text

* Review a paper on a pre-print server

* Use a free bibliometrics or altmetrics service \(e.g. [Impactstory](https://impactstory.org/), [Paperbuzz](https://paperbuzz.org/), [Altmetric bookmarklet](https://www.altmetric.com/products/free-tools/bookmarklet/), [Dimensions.ai](https://www.dimensions.ai/)\) to look up metrics for a paper, then write a short explanation of how exactly various metrics reported by each service are calculated \(it’s harder than you’d assume; this would get at the challenges of finding proper metrics documentation for even the seemingly most transparent services\)

## <img src="/Images/Icons/questions.png" width="150" height="150" />
### Sorular, engeller ve yaygın yanlış anlamalar
Q: Is research evaluation fair?

A: Research evaluation is as fair as its methods and evaluation techniques. Metrics and altmetrics try to measure research quality with research output quantity, which can be accurate, but does not have to be.


## <img src="/Images/Icons/output.png" width="150" height="150" />
### Öğrenme çıktıları

1. Trainees will be able to identify open peer review journals
2. Trainees will be aware of a range of metrics, their advantages and disadvantages

## <img src="/Images/Icons/magnifying_glass.png" width="150" height="150" />
### Ek okuma listesi

* Directorate-General for Research and Innovation (European Commission) (2017). Evaluation of Research Careers Fully Acknowledging Open Science Practices: Rewards, Incentives and/or Recognition for Researchers Practicing Open Science. [doi.org/10.2777/75255](https://doi.org/10.2777/75255)

* Hicks et al. (2015) Bibliometrics: The Leiden Manifesto for research metrics. [doi.org/10.1038/520429a](www.doi.org/10.1038/520429a), [leidenmanifesto.org](http://www.leidenmanifesto.org/)

* Peer Review the Nuts and Bolts (2012). A Guide for Early Career Researchers. [PDF](http://senseaboutscience.org/wp-content/uploads/2016/09/peer-review-the-nuts-and-bolts.pdf)


### Projeler ve Girişimler

* Make Data Count. [makedatacount.org](https://makedatacount.org/)

* NISO Alternative Assessment Metrics \(Altmetrics\) Initiative. [niso.org](http://www.niso.org/standards-committees/altmetrics)

* Open Rev. [openrev.org](https://en.wikipedia.org/wiki/Open_Rev)

* OpenUP Hub. [openuphub.eu](https://www.openuphub.eu/review)

* Peer Reviewers’ Openness Initiative. [opennessinitiative.org](https://opennessinitiative.org/)

* Peerage of Science. A free service for scientific peer review and publishing. [peerageofscience.org](https://www.peerageofscience.org/)

* Responsible Metrics. [responsiblemetrics.org](https://responsiblemetrics.org/)

* Snowball Metrics. Standardized research metrics - by the sector for the sector. [snowballmetrics.com](https://www.snowballmetrics.com/)
